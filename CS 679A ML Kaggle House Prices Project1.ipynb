{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8871030059213758\n",
      "28375.60517678195\n",
      "\n",
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 37.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 18648.6195 degrees.\n",
      "Accuracy = 88.51%.\n",
      "0.865313482983018\n",
      "30993.170424247866\n",
      "\n",
      "Model Performance\n",
      "Average Error: 16320.0084 degrees.\n",
      "Accuracy = 89.84%.\n",
      "0.8916841932638077\n",
      "27793.92380404642\n",
      "\n",
      "Improvement of 1.51%.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "training_filename = \"train.csv\"\n",
    "testing_filename = \"test.csv\"\n",
    "\n",
    "training_dataset = pd.read_csv(training_filename)\n",
    "testing_dataset = pd.read_csv(testing_filename)\n",
    "\n",
    "training_dataset = training_dataset.fillna(0)\n",
    "testing_dataset = testing_dataset.fillna(0)\n",
    "\n",
    "train_col_list = list(training_dataset.select_dtypes(include=['object']).columns)\n",
    "test_col_list = list(testing_dataset.select_dtypes(include=['object']).columns)\n",
    "\n",
    "for i in range(len(train_col_list)):\n",
    "    training_dataset = pd.get_dummies(training_dataset, columns=[train_col_list[i]])\n",
    "    \n",
    "Ids = training_dataset.pop('Id')\n",
    "salePrice = training_dataset.pop('SalePrice')\n",
    "\n",
    "    \n",
    "for j in range(len(test_col_list)):\n",
    "     testing_dataset = pd.get_dummies(testing_dataset, columns=[test_col_list[j]])\n",
    "        \n",
    "testIds = testing_dataset.pop('Id')\n",
    "\n",
    "trainCol = set(training_dataset.columns)\n",
    "testCol = set(testing_dataset.columns)\n",
    "trainRemove = list(trainCol - testCol)\n",
    "testRemove = list(testCol - trainCol)\n",
    "\n",
    "for i in range(len(trainRemove)):\n",
    "    training_dataset.pop(trainRemove[i])\n",
    "    \n",
    "for j in range(len(testRemove)):\n",
    "    testing_dataset.pop(testRemove[j])\n",
    "    \n",
    "train, test, trainSalePrice, testSalePrice = train_test_split(training_dataset, salePrice, test_size=0.2, random_state=1)\n",
    "\n",
    "# # XGB Model\n",
    "# xgbModel = xgb.XGBRegressor(learning_rate=0.1, colsample_bytree=0.5, subsample=1, n_estimators=500, reg_alpha=0.5, max_depth=3, gamma=1, random_state=1)\n",
    "# xgbModel = xgbModel.fit(train, trainSalePrice)\n",
    "# predicted = xgbModel.predict(test)\n",
    "# print(r2_score(testSalePrice, predicted))\n",
    "# print(mean_squared_error(testSalePrice, predicted, squared=False))\n",
    "# testxgbPred = xgbModel.predict(testing_dataset)\n",
    "# xgboutput = pd.DataFrame({'Id':testIds,\n",
    "#                           'SalePrice':testxgbPred})\n",
    "# xgboutput.to_csv('submission1.csv', index=False)\n",
    "# print()\n",
    "\n",
    "# Random Forest Model\n",
    "rfModel = RandomForestRegressor(n_estimators=500, max_depth=10, random_state=1)\n",
    "rfModel = rfModel.fit(train, trainSalePrice)\n",
    "rfPredicted = rfModel.predict(test)\n",
    "print(r2_score(testSalePrice, rfPredicted))\n",
    "print(mean_squared_error(testSalePrice, rfPredicted, squared=False))\n",
    "print()\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random.fit(train, trainSalePrice)\n",
    "rf_random.best_params_\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    print(r2_score(test_labels, predictions))\n",
    "    print(mean_squared_error(test_labels, predictions, squared=False))\n",
    "    print()\n",
    "    return accuracy\n",
    "\n",
    "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(train, trainSalePrice)\n",
    "base_accuracy = evaluate(base_model, test, testSalePrice)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, test, testSalePrice)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))\n",
    "testrf = best_random.predict(testing_dataset)\n",
    "rfoutput = pd.DataFrame({'Id':testIds,\n",
    "                          'SalePrice':testrf})\n",
    "rfoutput.to_csv('submission.csv', index=False)\n",
    "print()\n",
    "# # Gradient Boosting Model\n",
    "# gbModel = GradientBoostingRegressor(loss='huber', learning_rate=0.1, n_estimators=500, max_depth=5, random_state=1)\n",
    "# gbModel = gbModel.fit(train, trainSalePrice)\n",
    "# gbPredicted = gbModel.predict(test)\n",
    "# print(r2_score(testSalePrice, gbPredicted))\n",
    "# print(mean_squared_error(testSalePrice, gbPredicted, squared=False))\n",
    "# print()\n",
    "\n",
    "# # LGB Model\n",
    "# lgbModel = lgb.LGBMRegressor(max_depth=3, learning_rate=0.1, n_estimators=500, subsample_for_bin=600, colsample_bytree=0.5, reg_alpha=0.5, random_state=1)\n",
    "# lgbModel = lgbModel.fit(train, trainSalePrice)\n",
    "# lgbPredicted = lgbModel.predict(test)\n",
    "# print(r2_score(testSalePrice, lgbPredicted))\n",
    "# print(mean_squared_error(testSalePrice, lgbPredicted, squared=False))\n",
    "# testlgbPred = lgbModel.predict(testing_dataset)\n",
    "# lgboutput = pd.DataFrame({'Id':testIds,\n",
    "#                           'SalePrice':testlgbPred})\n",
    "# lgboutput.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
